{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "143b778d399a4328977f091cb82a207a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4212ec8a3d54a9786e205c66c83f4c7",
              "IPY_MODEL_0df6a3d3c6dc4d15ab1d2a99792a996c",
              "IPY_MODEL_b2d2488193d64328a51af9c7b11ea11d"
            ],
            "layout": "IPY_MODEL_23c16c1615a64af6a6c6eab751797176"
          }
        },
        "d4212ec8a3d54a9786e205c66c83f4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c07da8dcb0f496eb0fd0c85f9cbdfce",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5cc3dc1664564e2c9ab6cc67d1f7956f",
            "value": "Map:‚Äá100%"
          }
        },
        "0df6a3d3c6dc4d15ab1d2a99792a996c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a5121d6b2b472cb94913e32a4d7b4f",
            "max": 21767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbea98eb098742cf8ca41b23cf727ebe",
            "value": 21767
          }
        },
        "b2d2488193d64328a51af9c7b11ea11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faa00c6c88d74ff399141ab0a5671e82",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fdb75f2574514cb0aa39b24a0ef5dcfb",
            "value": "‚Äá21767/21767‚Äá[00:02&lt;00:00,‚Äá9760.61‚Äáexamples/s]"
          }
        },
        "23c16c1615a64af6a6c6eab751797176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c07da8dcb0f496eb0fd0c85f9cbdfce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc3dc1664564e2c9ab6cc67d1f7956f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97a5121d6b2b472cb94913e32a4d7b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbea98eb098742cf8ca41b23cf727ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "faa00c6c88d74ff399141ab0a5671e82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb75f2574514cb0aa39b24a0ef5dcfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fa23e916788451d9882e0323f774f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92adca5dd7424b038dd1258799384399",
              "IPY_MODEL_5ae3fe8c6a264c7b90ac47a9d18f13ea",
              "IPY_MODEL_ba40d1661d8b4f0ebbb0f17150e2237d"
            ],
            "layout": "IPY_MODEL_a22b0e14b61740d2b654618f8d547750"
          }
        },
        "92adca5dd7424b038dd1258799384399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c43e6fd61dd64b998596b6e91a5c4216",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bf925f8a8fa9433b8ffedda6185b5753",
            "value": "Map:‚Äá100%"
          }
        },
        "5ae3fe8c6a264c7b90ac47a9d18f13ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f974d03743413680700aaddafc2ed6",
            "max": 2800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d30444cbf80d48a989ba2a0ba5a146a7",
            "value": 2800
          }
        },
        "ba40d1661d8b4f0ebbb0f17150e2237d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aa81b18dc79414295feeeb3360400bd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6b5654fe4e0447bfa56625b9bb349fba",
            "value": "‚Äá2800/2800‚Äá[00:00&lt;00:00,‚Äá10296.18‚Äáexamples/s]"
          }
        },
        "a22b0e14b61740d2b654618f8d547750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43e6fd61dd64b998596b6e91a5c4216": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf925f8a8fa9433b8ffedda6185b5753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8f974d03743413680700aaddafc2ed6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d30444cbf80d48a989ba2a0ba5a146a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8aa81b18dc79414295feeeb3360400bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b5654fe4e0447bfa56625b9bb349fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silvsilvsilv/multilingualcodeswitchingthesis/blob/main/XLM_RoBERTa_with_LoRA_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XLM-RoBERTa + LoRA Fine-tuning: 5-Trial Hate Speech Detection\n",
        "# Multilingual (English, Tagalog, Cebuano) Binary Classification\n",
        "\n",
        "# ============================================================================\n",
        "# SECTION 1: Setup and Installation\n",
        "# ============================================================================\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q transformers datasets accelerate peft evaluate scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from datasets import Dataset\n",
        "import json"
      ],
      "metadata": {
        "id": "mYj0om2xnsM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb5d3e3-a695-41de-b963-563c45f3c51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 2: Configuration\n",
        "# ============================================================================\n",
        "\n",
        "# Training hyperparameters\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 1e-4\n",
        "FP16 = False  # Changed to False to avoid gradient scaling issues\n",
        "BF16 = torch.cuda.is_available() and torch.cuda.is_bf16_supported()  # Use BF16 if available\n",
        "LORA_R = 32\n",
        "LORA_ALPHA = 128\n",
        "LORA_DROPOUT = 0.1\n",
        "NUM_TRIALS = 5\n",
        "SEEDS = [42, 123, 2025, 7, 99]  # Custom seeds for each trial\n",
        "\n",
        "# Model configuration\n",
        "MODEL_NAME = \"xlm-roberta-base\"\n",
        "MAX_LENGTH = 192\n",
        "NUM_LABELS = 2\n",
        "\n",
        "# Optimization\n",
        "SCHEDULER = \"cosine\"\n",
        "WARMUP_RATIO = 0.05\n",
        "LABEL_SMOOTHING = 0.05\n",
        "\n",
        "# Set base paths (MODIFY THESE TO YOUR GOOGLE DRIVE PATHS)\n",
        "BASE_DIR = \"/content/drive/MyDrive/hate_speech_detection_cleaned\"\n",
        "DATA_DIR = f\"/content\"\n",
        "OUTPUT_DIR = f\"{BASE_DIR}/models\"\n",
        "RESULTS_DIR = f\"{BASE_DIR}/results\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Data file paths\n",
        "TRAIN_FILE = f\"{DATA_DIR}/unique_train_dataset_cleaned (1).csv\"\n",
        "VAL_FILE = f\"{DATA_DIR}/unique_validation_dataset_cleaned (1).csv\"\n",
        "TEST_FILE = f\"{DATA_DIR}/unique_test_dataset_cleaned (1).csv\"\n",
        "\n",
        "print(\"‚úì Configuration loaded\")\n",
        "print(f\"  Model: {MODEL_NAME}\")\n",
        "print(f\"  Trials: {NUM_TRIALS}\")\n",
        "print(f\"  Seeds: {SEEDS}\")\n",
        "print(f\"  Epochs per trial: {EPOCHS}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"  LoRA r={LORA_R}, alpha={LORA_ALPHA}\")\n",
        "print(f\"  FP16: {FP16}, BF16: {BF16}\")\n",
        "print(f\"  Output directory: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "xJ6Wx-CEns0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5162d7ad-35d2-4442-9175-16f575b013de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Configuration loaded\n",
            "  Model: xlm-roberta-base\n",
            "  Trials: 5\n",
            "  Seeds: [42, 123, 2025, 7, 99]\n",
            "  Epochs per trial: 10\n",
            "  Batch size: 16\n",
            "  Learning rate: 0.0001\n",
            "  LoRA r=32, alpha=128\n",
            "  FP16: False, BF16: True\n",
            "  Output directory: /content/drive/MyDrive/hate_speech_detection_cleaned/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 3: Utility Functions\n",
        "# ============================================================================\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"Set random seed for reproducibility\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def load_datasets():\n",
        "    \"\"\"Load and prepare datasets\"\"\"\n",
        "    print(\"\\nüìÇ Loading datasets...\")\n",
        "\n",
        "    train_df = pd.read_csv(TRAIN_FILE)\n",
        "    val_df = pd.read_csv(VAL_FILE)\n",
        "    test_df = pd.read_csv(TEST_FILE)\n",
        "\n",
        "    print(f\"  Train: {len(train_df)} samples\")\n",
        "    print(f\"  Validation: {len(val_df)} samples\")\n",
        "    print(f\"  Test: {len(test_df)} samples\")\n",
        "\n",
        "    # Convert to HF Dataset format\n",
        "    train_dataset = Dataset.from_pandas(train_df[['text', 'label']])\n",
        "    val_dataset = Dataset.from_pandas(val_df[['text', 'label']])\n",
        "    test_dataset = Dataset.from_pandas(test_df[['text', 'label']])\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset, test_df\n",
        "\n",
        "def tokenize_function(examples, tokenizer):\n",
        "    \"\"\"Tokenize text data\"\"\"\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH\n",
        "    )\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute evaluation metrics\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='macro', zero_division=0\n",
        "    )\n",
        "\n",
        "    micro_f1 = precision_recall_fscore_support(\n",
        "        labels, predictions, average='micro', zero_division=0\n",
        "    )[2]\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'macro_f1': f1,\n",
        "        'micro_f1': micro_f1\n",
        "    }\n",
        "\n",
        "def create_lora_model(model_name, num_labels):\n",
        "    \"\"\"Create model with LoRA configuration\"\"\"\n",
        "    # Load base model - use float32 to avoid FP16 gradient issues\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=num_labels,\n",
        "        torch_dtype=torch.float32  # Changed to float32 for stability\n",
        "    )\n",
        "\n",
        "    # Configure LoRA\n",
        "    lora_config = LoraConfig(\n",
        "        # task_type=TaskType.SEQ_CLS,\n",
        "        task_type=\"SEQ_CLS\",\n",
        "        r=LORA_R,\n",
        "        lora_alpha=LORA_ALPHA,\n",
        "        lora_dropout=LORA_DROPOUT,\n",
        "        target_modules=[\"query\", \"value\"],\n",
        "        bias=\"none\"\n",
        "    )\n",
        "\n",
        "    # Apply LoRA\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Wlb4E9_unvMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 4: Training Function\n",
        "# ============================================================================\n",
        "\n",
        "def train_single_trial(trial_num, train_dataset, val_dataset, tokenizer):\n",
        "    \"\"\"Train a single trial with specified seed\"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üöÄ TRIAL {trial_num}/{NUM_TRIALS}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Set seed for this trial using predefined seeds\n",
        "    seed = SEEDS[trial_num - 1]\n",
        "    set_seed(seed)\n",
        "    print(f\"  Seed: {seed}\")\n",
        "\n",
        "    # Create model with LoRA\n",
        "    model = create_lora_model(MODEL_NAME, NUM_LABELS)\n",
        "\n",
        "    # Define output directory for this trial\n",
        "    trial_output_dir = f\"{OUTPUT_DIR}/trial_{trial_num}\"\n",
        "    os.makedirs(trial_output_dir, exist_ok=True)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=trial_output_dir,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        weight_decay=0.01,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"macro_f1\",\n",
        "        greater_is_better=True,\n",
        "        fp16=False,  # Disabled FP16\n",
        "        bf16=BF16,  # Use BF16 if available\n",
        "        logging_dir=f\"{trial_output_dir}/logs\",\n",
        "        logging_steps=50,\n",
        "        seed=seed,\n",
        "        report_to=\"none\",\n",
        "        save_total_limit=2,\n",
        "        gradient_accumulation_steps=1,\n",
        "        dataloader_pin_memory=False,  # Additional stability\n",
        "        lr_scheduler_type=SCHEDULER,\n",
        "        warmup_ratio=WARMUP_RATIO,\n",
        "        label_smoothing_factor=LABEL_SMOOTHING,\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        processing_class=tokenizer,  # Updated from 'tokenizer' parameter\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    print(\"\\n  Training started...\")\n",
        "    train_result = trainer.train()\n",
        "\n",
        "    # Save final model\n",
        "    trainer.save_model(trial_output_dir)\n",
        "    tokenizer.save_pretrained(trial_output_dir)\n",
        "\n",
        "    # Get validation metrics\n",
        "    val_metrics = trainer.evaluate()\n",
        "\n",
        "    print(f\"\\n  ‚úì Trial {trial_num} completed\")\n",
        "    print(f\"    Validation Macro F1: {val_metrics['eval_macro_f1']:.4f}\")\n",
        "    print(f\"    Validation Precision: {val_metrics['eval_precision']:.4f}\")\n",
        "    print(f\"    Validation Recall: {val_metrics['eval_recall']:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'trial': trial_num,\n",
        "        'seed': seed,\n",
        "        'val_macro_f1': val_metrics['eval_macro_f1'],\n",
        "        'val_precision': val_metrics['eval_precision'],\n",
        "        'val_recall': val_metrics['eval_recall'],\n",
        "        'val_micro_f1': val_metrics['eval_micro_f1'],\n",
        "        'model_path': trial_output_dir\n",
        "    }"
      ],
      "metadata": {
        "id": "JDEqCk-SnxkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 5: Testing Function\n",
        "# ============================================================================\n",
        "\n",
        "def test_model(model_path, test_dataset, tokenizer, test_df):\n",
        "    \"\"\"Test a trained model and return detailed metrics\"\"\"\n",
        "    print(f\"\\n  Loading model from: {model_path}\")\n",
        "\n",
        "    # Load model\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_path,\n",
        "        local_files_only=True\n",
        "    )\n",
        "    model.eval()\n",
        "    model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Prepare test data\n",
        "    def tokenize_batch(batch):\n",
        "        return tokenizer(\n",
        "            batch['text'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=MAX_LENGTH,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "    # Make predictions\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(test_dataset), BATCH_SIZE):\n",
        "            batch = test_dataset[i:i+BATCH_SIZE]\n",
        "            inputs = tokenize_batch(batch)\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(batch['label'])\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='macro', zero_division=0\n",
        "    )\n",
        "\n",
        "    micro_f1 = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='micro', zero_division=0\n",
        "    )[2]\n",
        "\n",
        "    # Confusion matrix (flattened)\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "    cm_flat = cm.flatten().tolist()\n",
        "\n",
        "    return {\n",
        "        'test_precision': precision,\n",
        "        'test_recall': recall,\n",
        "        'test_macro_f1': f1,\n",
        "        'test_micro_f1': micro_f1,\n",
        "        'confusion_matrix': cm_flat,\n",
        "        'predictions': all_predictions,\n",
        "        'labels': all_labels\n",
        "    }\n"
      ],
      "metadata": {
        "id": "2pCArBANn3dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 6: Main Execution\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"XLM-RoBERTa + LoRA: Multi-Trial Hate Speech Detection\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Load datasets\n",
        "    train_dataset, val_dataset, test_dataset, test_df = load_datasets()\n",
        "\n",
        "    # Load tokenizer\n",
        "    print(\"\\nüî§ Loading tokenizer...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    # Tokenize datasets\n",
        "    print(\"  Tokenizing train and validation datasets...\")\n",
        "    train_dataset = train_dataset.map(\n",
        "        lambda x: tokenize_function(x, tokenizer),\n",
        "        batched=True\n",
        "    )\n",
        "    val_dataset = val_dataset.map(\n",
        "        lambda x: tokenize_function(x, tokenizer),\n",
        "        batched=True\n",
        "    )\n",
        "    # Test dataset tokenization will happen in the test_model function\n",
        "    # test_dataset = test_dataset.map(\n",
        "    #     lambda x: tokenize_function(x, tokenizer),\n",
        "    #     batched=True\n",
        "    # )\n",
        "\n",
        "    # Set format for PyTorch\n",
        "    train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "    val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "    # test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label']) # Format later in test_model\n",
        "\n",
        "    # Train all trials\n",
        "    all_trial_results = []\n",
        "\n",
        "    for trial_num in range(1, NUM_TRIALS + 1):\n",
        "        trial_result = train_single_trial(\n",
        "            trial_num,\n",
        "            train_dataset,\n",
        "            val_dataset,\n",
        "            tokenizer\n",
        "        )\n",
        "        all_trial_results.append(trial_result)\n",
        "\n",
        "    # Find best model based on validation macro F1\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä TRIAL SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    best_trial = max(all_trial_results, key=lambda x: x['val_macro_f1'])\n",
        "\n",
        "    for result in all_trial_results:\n",
        "        is_best = \"‚≠ê BEST\" if result['trial'] == best_trial['trial'] else \"\"\n",
        "        print(f\"Trial {result['trial']}: Val Macro F1 = {result['val_macro_f1']:.4f} {is_best}\")\n",
        "\n",
        "    print(f\"\\nüèÜ Best Model: Trial {best_trial['trial']}\")\n",
        "    print(f\"   Validation Macro F1: {best_trial['val_macro_f1']:.4f}\")\n",
        "    print(f\"   Model Path: {best_trial['model_path']}\")\n",
        "\n",
        "    # Test all models and save results\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üß™ TESTING ALL MODELS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    final_results = []\n",
        "\n",
        "    for trial_result in all_trial_results:\n",
        "        print(f\"\\nTesting Trial {trial_result['trial']}...\")\n",
        "\n",
        "        test_metrics = test_model(\n",
        "            trial_result['model_path'],\n",
        "            test_dataset, # Pass the original test_dataset\n",
        "            tokenizer,\n",
        "            test_df\n",
        "        )\n",
        "\n",
        "        # Combine trial and test results\n",
        "        combined_result = {\n",
        "            'trial': trial_result['trial'],\n",
        "            'seed': trial_result['seed'],\n",
        "            'val_precision': trial_result['val_precision'],\n",
        "            'val_recall': trial_result['val_recall'],\n",
        "            'val_macro_f1': trial_result['val_macro_f1'],\n",
        "            'val_micro_f1': trial_result['val_micro_f1'],\n",
        "            'test_precision': test_metrics['test_precision'],\n",
        "            'test_recall': test_metrics['test_recall'],\n",
        "            'test_macro_f1': test_metrics['test_macro_f1'],\n",
        "            'test_micro_f1': test_metrics['test_micro_f1'],\n",
        "            'cm_tn': test_metrics['confusion_matrix'][0],\n",
        "            'cm_fp': test_metrics['confusion_matrix'][1],\n",
        "            'cm_fn': test_metrics['confusion_matrix'][2],\n",
        "            'cm_tp': test_metrics['confusion_matrix'][3],\n",
        "            'is_best_model': trial_result['trial'] == best_trial['trial']\n",
        "        }\n",
        "\n",
        "        final_results.append(combined_result)\n",
        "\n",
        "        print(f\"  Test Macro F1: {test_metrics['test_macro_f1']:.4f}\")\n",
        "        print(f\"  Test Precision: {test_metrics['test_precision']:.4f}\")\n",
        "        print(f\"  Test Recall: {test_metrics['test_recall']:.4f}\")\n",
        "\n",
        "    # Save all results to CSV\n",
        "    results_df = pd.DataFrame(final_results)\n",
        "    results_file = f\"{RESULTS_DIR}/all_trials_results.csv\"\n",
        "    results_df.to_csv(results_file, index=False)\n",
        "    print(f\"\\n‚úì Results saved to: {results_file}\")\n",
        "\n",
        "    # Copy best model to dedicated directory\n",
        "    best_model_dir = f\"{OUTPUT_DIR}/best_model\"\n",
        "    print(f\"\\nüì¶ Copying best model to: {best_model_dir}\")\n",
        "\n",
        "    import shutil\n",
        "    if os.path.exists(best_model_dir):\n",
        "        shutil.rmtree(best_model_dir)\n",
        "    shutil.copytree(best_trial['model_path'], best_model_dir)\n",
        "\n",
        "    # Save best model info\n",
        "    best_model_info = {\n",
        "        'trial': best_trial['trial'],\n",
        "        'seed': best_trial['seed'],\n",
        "        'val_macro_f1': best_trial['val_macro_f1'],\n",
        "        'test_macro_f1': results_df[results_df['is_best_model'] == True]['test_macro_f1'].values[0],\n",
        "        'model_path': best_model_dir,\n",
        "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    }\n",
        "\n",
        "    with open(f\"{best_model_dir}/best_model_info.json\", 'w') as f:\n",
        "        json.dump(best_model_info, f, indent=2)\n",
        "\n",
        "    # Final summary\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚úÖ TRAINING COMPLETE\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Total trials: {NUM_TRIALS}\")\n",
        "    print(f\"Best trial: {best_trial['trial']}\")\n",
        "    print(f\"Best model saved to: {best_model_dir}\")\n",
        "    print(f\"All results saved to: {results_file}\")\n",
        "    print(\"\\nBest Model Performance:\")\n",
        "    best_result = results_df[results_df['is_best_model'] == True].iloc[0]\n",
        "    print(f\"  Validation Macro F1: {best_result['val_macro_f1']:.4f}\")\n",
        "    print(f\"  Test Macro F1: {best_result['test_macro_f1']:.4f}\")\n",
        "    print(f\"  Test Precision: {best_result['test_precision']:.4f}\")\n",
        "    print(f\"  Test Recall: {best_result['test_recall']:.4f}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "Eu8-GRn4n3_L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "143b778d399a4328977f091cb82a207a",
            "d4212ec8a3d54a9786e205c66c83f4c7",
            "0df6a3d3c6dc4d15ab1d2a99792a996c",
            "b2d2488193d64328a51af9c7b11ea11d",
            "23c16c1615a64af6a6c6eab751797176",
            "1c07da8dcb0f496eb0fd0c85f9cbdfce",
            "5cc3dc1664564e2c9ab6cc67d1f7956f",
            "97a5121d6b2b472cb94913e32a4d7b4f",
            "bbea98eb098742cf8ca41b23cf727ebe",
            "faa00c6c88d74ff399141ab0a5671e82",
            "fdb75f2574514cb0aa39b24a0ef5dcfb",
            "8fa23e916788451d9882e0323f774f76",
            "92adca5dd7424b038dd1258799384399",
            "5ae3fe8c6a264c7b90ac47a9d18f13ea",
            "ba40d1661d8b4f0ebbb0f17150e2237d",
            "a22b0e14b61740d2b654618f8d547750",
            "c43e6fd61dd64b998596b6e91a5c4216",
            "bf925f8a8fa9433b8ffedda6185b5753",
            "f8f974d03743413680700aaddafc2ed6",
            "d30444cbf80d48a989ba2a0ba5a146a7",
            "8aa81b18dc79414295feeeb3360400bd",
            "6b5654fe4e0447bfa56625b9bb349fba"
          ]
        },
        "outputId": "352e9572-92c5-45b5-c17b-6837d80cfc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "XLM-RoBERTa + LoRA: Multi-Trial Hate Speech Detection\n",
            "======================================================================\n",
            "\n",
            "üìÇ Loading datasets...\n",
            "  Train: 21767 samples\n",
            "  Validation: 2800 samples\n",
            "  Test: 2808 samples\n",
            "\n",
            "üî§ Loading tokenizer...\n",
            "  Tokenizing train and validation datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/21767 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "143b778d399a4328977f091cb82a207a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fa23e916788451d9882e0323f774f76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üöÄ TRIAL 1/5\n",
            "======================================================================\n",
            "  Seed: 42\n",
            "trainable params: 1,771,778 || all params: 279,816,964 || trainable%: 0.6332\n",
            "\n",
            "  Training started...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10888' max='13610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10888/13610 11:47 < 02:56, 15.39 it/s, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.433200</td>\n",
              "      <td>0.399851</td>\n",
              "      <td>0.852510</td>\n",
              "      <td>0.848003</td>\n",
              "      <td>0.847984</td>\n",
              "      <td>0.848571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.428000</td>\n",
              "      <td>0.438183</td>\n",
              "      <td>0.832508</td>\n",
              "      <td>0.831955</td>\n",
              "      <td>0.832026</td>\n",
              "      <td>0.832143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.380600</td>\n",
              "      <td>0.387157</td>\n",
              "      <td>0.853585</td>\n",
              "      <td>0.853624</td>\n",
              "      <td>0.853569</td>\n",
              "      <td>0.853571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.386900</td>\n",
              "      <td>0.372860</td>\n",
              "      <td>0.857947</td>\n",
              "      <td>0.857764</td>\n",
              "      <td>0.857812</td>\n",
              "      <td>0.857857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.376400</td>\n",
              "      <td>0.368837</td>\n",
              "      <td>0.862515</td>\n",
              "      <td>0.862450</td>\n",
              "      <td>0.862473</td>\n",
              "      <td>0.862500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.354700</td>\n",
              "      <td>0.375677</td>\n",
              "      <td>0.868397</td>\n",
              "      <td>0.867236</td>\n",
              "      <td>0.867347</td>\n",
              "      <td>0.867500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.272700</td>\n",
              "      <td>0.387778</td>\n",
              "      <td>0.866776</td>\n",
              "      <td>0.863458</td>\n",
              "      <td>0.863542</td>\n",
              "      <td>0.863929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.302000</td>\n",
              "      <td>0.397792</td>\n",
              "      <td>0.863364</td>\n",
              "      <td>0.860646</td>\n",
              "      <td>0.860738</td>\n",
              "      <td>0.861071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [175/175 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  ‚úì Trial 1 completed\n",
            "    Validation Macro F1: 0.8673\n",
            "    Validation Precision: 0.8684\n",
            "    Validation Recall: 0.8672\n",
            "\n",
            "======================================================================\n",
            "üöÄ TRIAL 2/5\n",
            "======================================================================\n",
            "  Seed: 123\n",
            "trainable params: 1,771,778 || all params: 279,816,964 || trainable%: 0.6332\n",
            "\n",
            "  Training started...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13610' max='13610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13610/13610 14:39, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.428700</td>\n",
              "      <td>0.437912</td>\n",
              "      <td>0.834299</td>\n",
              "      <td>0.828933</td>\n",
              "      <td>0.827630</td>\n",
              "      <td>0.828214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.404000</td>\n",
              "      <td>0.410948</td>\n",
              "      <td>0.848392</td>\n",
              "      <td>0.846509</td>\n",
              "      <td>0.845916</td>\n",
              "      <td>0.846071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.372100</td>\n",
              "      <td>0.381148</td>\n",
              "      <td>0.857903</td>\n",
              "      <td>0.854516</td>\n",
              "      <td>0.854571</td>\n",
              "      <td>0.855000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.368700</td>\n",
              "      <td>0.369188</td>\n",
              "      <td>0.860748</td>\n",
              "      <td>0.859754</td>\n",
              "      <td>0.859855</td>\n",
              "      <td>0.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.347700</td>\n",
              "      <td>0.383293</td>\n",
              "      <td>0.862860</td>\n",
              "      <td>0.855716</td>\n",
              "      <td>0.855601</td>\n",
              "      <td>0.856429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.345000</td>\n",
              "      <td>0.376946</td>\n",
              "      <td>0.862800</td>\n",
              "      <td>0.860308</td>\n",
              "      <td>0.860404</td>\n",
              "      <td>0.860714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.315300</td>\n",
              "      <td>0.396652</td>\n",
              "      <td>0.863087</td>\n",
              "      <td>0.862719</td>\n",
              "      <td>0.862790</td>\n",
              "      <td>0.862857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.308300</td>\n",
              "      <td>0.391964</td>\n",
              "      <td>0.868506</td>\n",
              "      <td>0.864863</td>\n",
              "      <td>0.864943</td>\n",
              "      <td>0.865357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.304400</td>\n",
              "      <td>0.402741</td>\n",
              "      <td>0.863818</td>\n",
              "      <td>0.862581</td>\n",
              "      <td>0.862689</td>\n",
              "      <td>0.862857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.292200</td>\n",
              "      <td>0.400164</td>\n",
              "      <td>0.865093</td>\n",
              "      <td>0.863626</td>\n",
              "      <td>0.863737</td>\n",
              "      <td>0.863929</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [175/175 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  ‚úì Trial 2 completed\n",
            "    Validation Macro F1: 0.8649\n",
            "    Validation Precision: 0.8685\n",
            "    Validation Recall: 0.8649\n",
            "\n",
            "======================================================================\n",
            "üöÄ TRIAL 3/5\n",
            "======================================================================\n",
            "  Seed: 2025\n",
            "trainable params: 1,771,778 || all params: 279,816,964 || trainable%: 0.6332\n",
            "\n",
            "  Training started...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13610' max='13610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13610/13610 14:40, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.467000</td>\n",
              "      <td>0.403003</td>\n",
              "      <td>0.841264</td>\n",
              "      <td>0.840075</td>\n",
              "      <td>0.840157</td>\n",
              "      <td>0.840357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.399400</td>\n",
              "      <td>0.385056</td>\n",
              "      <td>0.852955</td>\n",
              "      <td>0.852955</td>\n",
              "      <td>0.852857</td>\n",
              "      <td>0.852857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.374400</td>\n",
              "      <td>0.373469</td>\n",
              "      <td>0.863566</td>\n",
              "      <td>0.862619</td>\n",
              "      <td>0.862722</td>\n",
              "      <td>0.862857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.363200</td>\n",
              "      <td>0.385204</td>\n",
              "      <td>0.858607</td>\n",
              "      <td>0.858639</td>\n",
              "      <td>0.858570</td>\n",
              "      <td>0.858571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.338000</td>\n",
              "      <td>0.375989</td>\n",
              "      <td>0.869328</td>\n",
              "      <td>0.865186</td>\n",
              "      <td>0.865252</td>\n",
              "      <td>0.865714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>0.370383</td>\n",
              "      <td>0.869717</td>\n",
              "      <td>0.869102</td>\n",
              "      <td>0.869194</td>\n",
              "      <td>0.869286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.317200</td>\n",
              "      <td>0.390023</td>\n",
              "      <td>0.873076</td>\n",
              "      <td>0.868366</td>\n",
              "      <td>0.868426</td>\n",
              "      <td>0.868929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.304300</td>\n",
              "      <td>0.388271</td>\n",
              "      <td>0.871154</td>\n",
              "      <td>0.869303</td>\n",
              "      <td>0.869423</td>\n",
              "      <td>0.869643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>0.387973</td>\n",
              "      <td>0.867013</td>\n",
              "      <td>0.866214</td>\n",
              "      <td>0.866314</td>\n",
              "      <td>0.866429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.307100</td>\n",
              "      <td>0.387866</td>\n",
              "      <td>0.865960</td>\n",
              "      <td>0.865139</td>\n",
              "      <td>0.865239</td>\n",
              "      <td>0.865357</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [175/175 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  ‚úì Trial 3 completed\n",
            "    Validation Macro F1: 0.8694\n",
            "    Validation Precision: 0.8712\n",
            "    Validation Recall: 0.8693\n",
            "\n",
            "======================================================================\n",
            "üöÄ TRIAL 4/5\n",
            "======================================================================\n",
            "  Seed: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,771,778 || all params: 279,816,964 || trainable%: 0.6332\n",
            "\n",
            "  Training started...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13610' max='13610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13610/13610 14:42, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.421300</td>\n",
              "      <td>0.416777</td>\n",
              "      <td>0.844344</td>\n",
              "      <td>0.837495</td>\n",
              "      <td>0.837273</td>\n",
              "      <td>0.838214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.393400</td>\n",
              "      <td>0.379945</td>\n",
              "      <td>0.858035</td>\n",
              "      <td>0.854893</td>\n",
              "      <td>0.854957</td>\n",
              "      <td>0.855357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.415233</td>\n",
              "      <td>0.860079</td>\n",
              "      <td>0.837997</td>\n",
              "      <td>0.836554</td>\n",
              "      <td>0.839286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.369800</td>\n",
              "      <td>0.386173</td>\n",
              "      <td>0.869857</td>\n",
              "      <td>0.862122</td>\n",
              "      <td>0.862021</td>\n",
              "      <td>0.862857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.364400</td>\n",
              "      <td>0.381126</td>\n",
              "      <td>0.867176</td>\n",
              "      <td>0.867082</td>\n",
              "      <td>0.867113</td>\n",
              "      <td>0.867143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.328100</td>\n",
              "      <td>0.385173</td>\n",
              "      <td>0.873077</td>\n",
              "      <td>0.869902</td>\n",
              "      <td>0.870009</td>\n",
              "      <td>0.870357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.343000</td>\n",
              "      <td>0.392998</td>\n",
              "      <td>0.872741</td>\n",
              "      <td>0.868389</td>\n",
              "      <td>0.868461</td>\n",
              "      <td>0.868929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.302800</td>\n",
              "      <td>0.386348</td>\n",
              "      <td>0.874543</td>\n",
              "      <td>0.872897</td>\n",
              "      <td>0.873022</td>\n",
              "      <td>0.873214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.292100</td>\n",
              "      <td>0.392377</td>\n",
              "      <td>0.874240</td>\n",
              "      <td>0.872936</td>\n",
              "      <td>0.873056</td>\n",
              "      <td>0.873214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.256400</td>\n",
              "      <td>0.392740</td>\n",
              "      <td>0.874216</td>\n",
              "      <td>0.873350</td>\n",
              "      <td>0.873458</td>\n",
              "      <td>0.873571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [175/175 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  ‚úì Trial 4 completed\n",
            "    Validation Macro F1: 0.8735\n",
            "    Validation Precision: 0.8742\n",
            "    Validation Recall: 0.8734\n",
            "\n",
            "======================================================================\n",
            "üöÄ TRIAL 5/5\n",
            "======================================================================\n",
            "  Seed: 99\n",
            "trainable params: 1,771,778 || all params: 279,816,964 || trainable%: 0.6332\n",
            "\n",
            "  Training started...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13610' max='13610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13610/13610 14:43, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.468200</td>\n",
              "      <td>0.392056</td>\n",
              "      <td>0.847945</td>\n",
              "      <td>0.847303</td>\n",
              "      <td>0.847385</td>\n",
              "      <td>0.847500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.387800</td>\n",
              "      <td>0.386845</td>\n",
              "      <td>0.861703</td>\n",
              "      <td>0.859632</td>\n",
              "      <td>0.859734</td>\n",
              "      <td>0.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.370200</td>\n",
              "      <td>0.383793</td>\n",
              "      <td>0.858532</td>\n",
              "      <td>0.856518</td>\n",
              "      <td>0.855919</td>\n",
              "      <td>0.856071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.360808</td>\n",
              "      <td>0.871405</td>\n",
              "      <td>0.866953</td>\n",
              "      <td>0.867016</td>\n",
              "      <td>0.867500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.368900</td>\n",
              "      <td>0.368569</td>\n",
              "      <td>0.868439</td>\n",
              "      <td>0.865255</td>\n",
              "      <td>0.865348</td>\n",
              "      <td>0.865714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.333400</td>\n",
              "      <td>0.369418</td>\n",
              "      <td>0.869678</td>\n",
              "      <td>0.868688</td>\n",
              "      <td>0.868796</td>\n",
              "      <td>0.868929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.285200</td>\n",
              "      <td>0.383889</td>\n",
              "      <td>0.870697</td>\n",
              "      <td>0.870730</td>\n",
              "      <td>0.870706</td>\n",
              "      <td>0.870714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.295900</td>\n",
              "      <td>0.388349</td>\n",
              "      <td>0.874552</td>\n",
              "      <td>0.873711</td>\n",
              "      <td>0.873818</td>\n",
              "      <td>0.873929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.282600</td>\n",
              "      <td>0.392819</td>\n",
              "      <td>0.874461</td>\n",
              "      <td>0.873312</td>\n",
              "      <td>0.873429</td>\n",
              "      <td>0.873571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.301600</td>\n",
              "      <td>0.391797</td>\n",
              "      <td>0.872697</td>\n",
              "      <td>0.871522</td>\n",
              "      <td>0.871638</td>\n",
              "      <td>0.871786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [175/175 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  ‚úì Trial 5 completed\n",
            "    Validation Macro F1: 0.8738\n",
            "    Validation Precision: 0.8746\n",
            "    Validation Recall: 0.8737\n",
            "\n",
            "======================================================================\n",
            "üìä TRIAL SUMMARY\n",
            "======================================================================\n",
            "Trial 1: Val Macro F1 = 0.8673 \n",
            "Trial 2: Val Macro F1 = 0.8649 \n",
            "Trial 3: Val Macro F1 = 0.8694 \n",
            "Trial 4: Val Macro F1 = 0.8735 \n",
            "Trial 5: Val Macro F1 = 0.8738 ‚≠ê BEST\n",
            "\n",
            "üèÜ Best Model: Trial 5\n",
            "   Validation Macro F1: 0.8738\n",
            "   Model Path: /content/drive/MyDrive/hate_speech_detection_cleaned/models/trial_5\n",
            "\n",
            "======================================================================\n",
            "üß™ TESTING ALL MODELS\n",
            "======================================================================\n",
            "\n",
            "Testing Trial 1...\n",
            "\n",
            "  Loading model from: /content/drive/MyDrive/hate_speech_detection_cleaned/models/trial_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Test Macro F1: 0.8700\n",
            "  Test Precision: 0.8709\n",
            "  Test Recall: 0.8701\n",
            "\n",
            "Testing Trial 2...\n",
            "\n",
            "  Loading model from: /content/drive/MyDrive/hate_speech_detection_cleaned/models/trial_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Test Macro F1: 0.8713\n",
            "  Test Precision: 0.8730\n",
            "  Test Recall: 0.8716\n",
            "\n",
            "Testing Trial 3...\n",
            "\n",
            "  Loading model from: /content/drive/MyDrive/hate_speech_detection_cleaned/models/trial_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Test Macro F1: 0.8696\n",
            "  Test Precision: 0.8710\n",
            "  Test Recall: 0.8698\n",
            "\n",
            "Testing Trial 4...\n",
            "\n",
            "  Loading model from: /content/drive/MyDrive/hate_speech_detection_cleaned/models/trial_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Test Macro F1: 0.8704\n",
            "  Test Precision: 0.8707\n",
            "  Test Recall: 0.8704\n",
            "\n",
            "Testing Trial 5...\n",
            "\n",
            "  Loading model from: /content/drive/MyDrive/hate_speech_detection_cleaned/models/trial_5\n",
            "  Test Macro F1: 0.8664\n",
            "  Test Precision: 0.8668\n",
            "  Test Recall: 0.8665\n",
            "\n",
            "‚úì Results saved to: /content/drive/MyDrive/hate_speech_detection_cleaned/results/all_trials_results.csv\n",
            "\n",
            "üì¶ Copying best model to: /content/drive/MyDrive/hate_speech_detection_cleaned/models/best_model\n",
            "\n",
            "======================================================================\n",
            "‚úÖ TRAINING COMPLETE\n",
            "======================================================================\n",
            "Total trials: 5\n",
            "Best trial: 5\n",
            "Best model saved to: /content/drive/MyDrive/hate_speech_detection_cleaned/models/best_model\n",
            "All results saved to: /content/drive/MyDrive/hate_speech_detection_cleaned/results/all_trials_results.csv\n",
            "\n",
            "Best Model Performance:\n",
            "  Validation Macro F1: 0.8738\n",
            "  Test Macro F1: 0.8664\n",
            "  Test Precision: 0.8668\n",
            "  Test Recall: 0.8665\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}